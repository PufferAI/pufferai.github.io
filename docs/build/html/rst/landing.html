<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Emulation" href="api.html" /><link rel="prev" title="Index" href="../index.html" />

    <!-- Generated with Sphinx 5.0.0 and Furo 2023.03.27 -->
        <title>Libraries - PufferLib 0.6.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-foreground-primary: black;
  --color-foreground-secondary: #005050;
  --color-foreground-muted: #005050;
  --color-foreground-border: #878787;
  --color-background-primary: white;
  --color-background-secondary: #bbcccc;
  --color-background-hover: #efeff4ff;
  --color-background-hover--transparent: #efeff400;
  --color-background-border: #005050;
  --color-background-item: #ccc;
  --color-announcement-background: #000000dd;
  --color-announcement-text: #eeebee;
  --color-brand-primary: black;
  --color-brand-content: black;
  --color-inline-code-background: #f8f9fb;
  --color-highlighted-background: #ddeeff;
  --color-guilabel-background: #ddeeff80;
  --color-guilabel-border: #bedaf580;
  --color-card-background: #bbcccc;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-problematic: #ee5151;
  --color-foreground-primary: #f1f1f1;
  --color-foreground-secondary: #00bbbb;
  --color-foreground-muted: #00bbbb;
  --color-foreground-border: #666666;
  --color-background-primary: #061a1a;
  --color-background-secondary: #000000;
  --color-background-hover: #1e2124ff;
  --color-background-hover--transparent: #1e212400;
  --color-background-border: #303335;
  --color-background-item: #444;
  --color-announcement-background: #000000dd;
  --color-announcement-text: #eeebee;
  --color-brand-primary: #00bbbb;
  --color-brand-content: #00bbbb;
  --color-highlighted-background: #083563;
  --color-guilabel-background: #08356380;
  --color-guilabel-border: #13395f80;
  --color-admonition-background: #18181a;
  --color-card-border: #1a1c1e;
  --color-card-background: #000000;
  --color-card-marginals-background: #1e2124ff;
  --color-inline-code-background: #00000000;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-problematic: #ee5151;
  --color-foreground-primary: #f1f1f1;
  --color-foreground-secondary: #00bbbb;
  --color-foreground-muted: #00bbbb;
  --color-foreground-border: #666666;
  --color-background-primary: #061a1a;
  --color-background-secondary: #000000;
  --color-background-hover: #1e2124ff;
  --color-background-hover--transparent: #1e212400;
  --color-background-border: #303335;
  --color-background-item: #444;
  --color-announcement-background: #000000dd;
  --color-announcement-text: #eeebee;
  --color-brand-primary: #00bbbb;
  --color-brand-content: #00bbbb;
  --color-highlighted-background: #083563;
  --color-guilabel-background: #08356380;
  --color-guilabel-border: #13395f80;
  --color-admonition-background: #18181a;
  --color-card-border: #1a1c1e;
  --color-card-background: #000000;
  --color-card-marginals-background: #1e2124ff;
  --color-inline-code-background: #00000000;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">PufferLib 0.6.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">PufferLib 0.6.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="#environments">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="#current-limitations">Current Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="#license">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">Emulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#environments">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#models">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#vectorization">Vectorization</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#cleanrl-integration">CleanRL Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#sb3-binding">SB3 Binding</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html#rllib-binding">RLlib Binding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">🌊 Ocean</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ocean.html">Squared</a></li>
<li class="toctree-l1"><a class="reference internal" href="ocean.html#password-exploration-environment">Password (exploration environment)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ocean.html#stochastic">Stochastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="ocean.html#memory">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="ocean.html#bandit">Bandit</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Blog</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="blog.html">🐡🌊 An Ocean of Environments for Learning Pufferfish</a></li>
<li class="toctree-l1"><a class="reference internal" href="blog.html#pufferlib-0-5-a-bigger-envpool-for-growing-puffers">PufferLib 0.5: A Bigger EnvPool for Growing Puffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="blog.html#pufferlib-0-4-ready-to-take-on-bigger-fish">PufferLib 0.4: Ready to Take on Bigger Fish</a></li>
<li class="toctree-l1"><a class="reference internal" href="blog.html#pufferlib-0-2-ready-to-take-on-the-big-fish">PufferLib 0.2: Ready to Take on the Big Fish</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="line-block">
<div class="line"><br /></div>
</div>
<p>You have an environment, a PyTorch model, and a reinforcement learning library that are designed to work together but don’t. PufferLib provides one-line wrappers that make them play nice.</p>
<div class="sd-card sd-sphinx-override sd-w-75 sd-mt-4 sd-mb-2 sd-ml-auto sd-mr-auto sd-shadow-sm sd-card-hover sd-text-center docutils">
<div class="sd-card-body docutils">
<p class="sd-card-text"><strong>Click to Demo PufferLib in Colab</strong></p>
</div>
<a class="sd-stretched-link reference external" href="https://colab.research.google.com/drive/142tl_9MiEDXX-E5-6kjwZsOmRYPcFrFU?usp=sharing"></a></div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<center>
  <video width=100% height="auto" nocontrols autoplay playsinline muted loop>
    <source src="../_static/banner.webm" type="video/webm">
    <source src="../_static/banner.mp4" type="video/mp4">
    Your browser does not support this video.
  </video>
</center><div style="text-align: center;">
    <div style="display: flex; align-items: center; justify-content: center; margin: auto;">
        <div style="flex-shrink: 0; width: 60px; margin-right: 20px;">
            <a href="https://github.com/pufferai/pufferlib" target="_blank">
                <img src="https://img.shields.io/github/stars/pufferai/pufferlib?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star pufferai/pufferlib" width="60px">
            </a>
        </div>
        <a href="https://discord.gg/puffer" target="_blank" style="margin-right: 20px;">
            <img src="https://dcbadge.vercel.app/api/server/puffer?style=plastic" alt="Discord">
        </a>
        <a href="https://twitter.com/jsuarez5341" target="_blank">
            <img src="https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&label=Follow%20%40jsuarez5341" alt="Twitter">
        </a>
    </div>
</div><div class="line-block">
<div class="line"><br /></div>
</div>
<p>Join our community Discord for support and Discussion, follow my Twitter for news, and star the repo to feed the puffer. We also have a <a class="reference download internal" download="" href="../_downloads/b6289fa6a05068cc61ddac77ec727f3f/neurips_2023_aloe.pdf"><code class="xref download docutils literal notranslate"><span class="pre">Whitepaper</span></code></a> featured at the NeurIPS 2023 ALOE workshop.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Installation<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="sd-tab-set docutils">
<input checked="checked" id="sd-tab-item-0" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-0">
PufferTank</label><div class="sd-tab-content docutils">
<p class="sd-card-text"><a class="reference external" href="https://github.com/pufferai/puffertank">PufferTank</a> is a GPU container with PufferLib and dependencies for all environments in the registry, including some that are slow and tricky to install.</p>
<p class="sd-card-text">If you have not used containers before and just want everything to work, clone the repository and open it in VSCode. You will need to install the Dev Container plugin as well as Docker Desktop. VSCode will then detect the settings in .devcontainer and set up the container for you.</p>
</div>
<input id="sd-tab-item-1" name="sd-tab-set-0" type="radio">
</input><label class="sd-tab-label" for="sd-tab-item-1">
Pip</label><div class="sd-tab-content docutils">
<p class="sd-card-text">PufferLib is also available as a standard pip package.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pufferlib</span>
</pre></div>
</div>
<p class="sd-card-text">To install additional environments and frameworks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pufferlib</span><span class="p">[</span><span class="n">nmmo</span><span class="p">,</span><span class="n">cleanrl</span><span class="p">]</span>
</pre></div>
</div>
<p class="sd-card-text">Note that some environments require additional non-pip dependencies. Follow the additional setup from the maintainers of that environment, or just use PufferTank.</p>
</div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Contributors<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Joseph Suarez</strong>: Creator and developer of PufferLib</p>
<p class="sd-card-text"><strong>David Bloomin</strong>: 0.4 policy pool/store/selector</p>
<p class="sd-card-text"><strong>Nick Jenkins</strong>: Layout for the system architecture diagram. Adversary.design.</p>
<p class="sd-card-text"><strong>Andranik Tigranyan</strong>: Streamline and animate the pufferfish. Hire him on UpWork if you like what you see here.</p>
<p class="sd-card-text"><strong>Sara Earle</strong>: Original pufferfish model. Hire her on UpWork if you like what you see here.</p>
</div>
</details><p><strong>You can open this guide in a Colab notebook by clicking the demo button at the top of this page</strong></p>
<p>Complex environments may have heirarchical observations and actions, variable numbers of agents, and other quirks that make them difficult to work with and incompatible with standard reinforcement learning libraries. PufferLib’s emulation layer makes every environment look like it has flat observations/actions and a constant number of agents. Here’s how it works with NetHack and Neural MMO, two notoriously complex environments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pufferlib.emulation</span>
<span class="kn">import</span> <span class="nn">pufferlib.wrappers</span>

<span class="kn">import</span> <span class="nn">nle</span><span class="o">,</span> <span class="nn">nmmo</span>

<span class="k">def</span> <span class="nf">nmmo_creator</span><span class="p">():</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">nmmo</span><span class="o">.</span><span class="n">Env</span><span class="p">()</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">PettingZooTruncatedWrapper</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">emulation</span><span class="o">.</span><span class="n">PettingZooPufferEnv</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">nethack_creator</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">emulation</span><span class="o">.</span><span class="n">GymnasiumPufferEnv</span><span class="p">(</span><span class="n">env_creator</span><span class="o">=</span><span class="n">nle</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">NLE</span><span class="p">)</span>
</pre></div>
</div>
<p>The wrappers give you back a Gymnasium/PettingZoo compliant environment. There is no loss of generality and no change to the underlying environment. You can wrap environments by class, creator function, or object, with or without additional arguments. These wrappers enable us to make some optimizations to vectorization code that would be difficult to implement otherwise. You can choose from a variety of vectorization backends. They all share the same interface with synchronous and asynchronous options.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pufferlib.vectorization</span>

<span class="n">vec</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">vectorization</span><span class="o">.</span><span class="n">Serial</span>
<span class="c1"># vec = pufferlib.vectorization.Multiprocessing</span>
<span class="c1"># vec = pufferlib.vectorization.Ray</span>

<span class="c1"># Vectorization API. Specify total number of environments and number per worker</span>
<span class="c1"># Setting env_pool=True can be much faster but requires some tweaks to learning code</span>
<span class="n">envs</span> <span class="o">=</span> <span class="n">vec</span><span class="p">(</span><span class="n">nmmo_creator</span><span class="p">,</span> <span class="n">num_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">envs_per_worker</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">env_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Synchronous API - reset/step</span>
<span class="c1"># obs = envs.reset()[0]</span>

<span class="c1"># Asynchronous API - async_reset, send/recv</span>
<span class="n">envs</span><span class="o">.</span><span class="n">async_reset</span><span class="p">()</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">recv</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Our backends support asynchronous on-policy sampling through a Python implementation of EnvPool. This makes them <em>faster</em> than the implementations that ship with most RL libraries. We suggest Serial for debugging and Multiprocessing for most training runs. Ray is a good option if you need to scale beyond a single machine.</p>
<p>PufferLib allows you to write vanilla PyTorch policies and use them with multiple learning libraries. We take care of the details of converting between the different APIs. Here’s a policy that will work with <em>any</em> environment, with a one-line wrapper for CleanRL.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">pufferlib.frameworks.cleanrl</span>

<span class="k">class</span> <span class="nc">Policy</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
            <span class="n">envs</span><span class="o">.</span><span class="n">single_observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">envs</span><span class="o">.</span><span class="n">single_action_space</span><span class="o">.</span><span class="n">nvec</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_outputs</span><span class="p">):</span>
        <span class="n">env_outputs</span> <span class="o">=</span> <span class="n">env_outputs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">env_outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">env_outputs</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="n">dec</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span> <span class="k">for</span> <span class="n">dec</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">]</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_head</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">actions</span><span class="p">,</span> <span class="n">value</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">Policy</span><span class="p">(</span><span class="n">envs</span><span class="o">.</span><span class="n">driver_env</span><span class="p">)</span>
<span class="n">cleanrl_policy</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">frameworks</span><span class="o">.</span><span class="n">cleanrl</span><span class="o">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
<span class="n">actions</span> <span class="o">=</span> <span class="n">cleanrl_policy</span><span class="o">.</span><span class="n">get_action_and_value</span><span class="p">(</span><span class="n">obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">terminals</span><span class="p">,</span> <span class="n">truncateds</span><span class="p">,</span> <span class="n">infos</span><span class="p">,</span> <span class="n">env_id</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
<span class="n">envs</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>There’s also an optional policy base class for PufferLib. It just breaks the forward pass into an encode and decode step, which allows us to handle recurrance for you. So far, the code above is fully general and does not rely on PufferLib support for specific environments. For convenience, we also provide environment hooks with standard wrappers and baseline models. Here’s a complete example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">pufferlib.models</span>
<span class="kn">import</span> <span class="nn">pufferlib.vectorization</span>
<span class="kn">import</span> <span class="nn">pufferlib.frameworks.cleanrl</span>
<span class="kn">import</span> <span class="nn">pufferlib.environments.nmmo</span>

<span class="n">envs</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">vectorization</span><span class="o">.</span><span class="n">Multiprocessing</span><span class="p">(</span>
    <span class="n">env_creator</span><span class="o">=</span><span class="n">pufferlib</span><span class="o">.</span><span class="n">environments</span><span class="o">.</span><span class="n">nmmo</span><span class="o">.</span><span class="n">make_env</span><span class="p">,</span>
    <span class="n">num_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">envs_per_worker</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">policy</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">environments</span><span class="o">.</span><span class="n">nmmo</span><span class="o">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">envs</span><span class="o">.</span><span class="n">driver_env</span><span class="p">)</span>
<span class="n">cleanrl_policy</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">frameworks</span><span class="o">.</span><span class="n">cleanrl</span><span class="o">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>

<span class="n">env_outputs</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">env_outputs</span><span class="p">)</span>
<span class="n">actions</span> <span class="o">=</span> <span class="n">cleanrl_policy</span><span class="o">.</span><span class="n">get_action_and_value</span><span class="p">(</span><span class="n">obs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">terminals</span><span class="p">,</span> <span class="n">truncateds</span><span class="p">,</span> <span class="n">infos</span><span class="p">,</span> <span class="n">env_id</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
<span class="n">envs</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It’s that simple – almost. If you have an environment with structured observations, you’ll have to unpack them in the network forward pass since PufferLib will flatten them in emulation. We provide a utility for this.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">obs</span> <span class="o">=</span> <span class="n">pufferlib</span><span class="o">.</span><span class="n">emulation</span><span class="o">.</span><span class="n">unpack_batched_obs</span><span class="p">(</span>
    <span class="n">env_outputs</span><span class="p">,</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">driver_env</span><span class="o">.</span><span class="n">flat_observation_space</span><span class="p">,</span>
    <span class="n">envs</span><span class="o">.</span><span class="n">driver_env</span><span class="o">.</span><span class="n">flat_observation_structure</span>
<span class="p">)</span>
</pre></div>
</div>
<p>That’s all you need to get started. The PufferLib repository contains full-length CleanRL scripts with PufferLib integration. SB3 and other integrations coming soon!</p>
<section id="libraries">
<h1>Libraries<a class="headerlink" href="#libraries" title="Permalink to this heading">#</a></h1>
<p>PufferLib’s emulation layer adheres to the Gym and PettingZoo APIs: you can use it with <em>any</em> environment and learning library (subject to Limitations). The libraries and environments below are just the ones we’ve tested. We also provide additional tools to make them easier to work with.</p>
<p>PufferLib provides <em>pufferlib.frameworks</em> for the the learning libraries below. These are short wrappers over your vanilla PyTorch policy that handles learning library API details for you. Additionally, if you use our <em>optional</em> model API, which just requires you to split your <em>forward</em> function into an <em>encode</em> and <em>decode</em> portion, we can handle recurrance for you. This is the approach we use in our default policies.</p>
<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/vwxyzjn/cleanrl" target="_blank">
            <img src="https://img.shields.io/github/stars/vwxyzjn/cleanrl?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star CleanRL" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/vwxyzjn/cleanrl">CleanRL</a> provides single-file RL implementations suited for 80+% of academic research. It was designed for simple environments like Atari, but with PufferLib, you can use it with just about anything.</p>
    </div>
</div><div class="sd-card sd-sphinx-override sd-w-75 sd-mt-4 sd-mb-2 sd-ml-auto sd-mr-auto sd-shadow-sm sd-card-hover sd-text-center docutils">
<div class="sd-card-body docutils">
<p class="sd-card-text"><strong>Click to Demo PufferLib + CleanRL in Colab</strong></p>
</div>
<a class="sd-stretched-link reference external" href="https://colab.research.google.com/drive/1OMcaJnCAF1UiCJxKIxSS-RdZTuonItYT?usp=sharing"></a></div>
<p>Or view it on GitHub <a class="reference external" href="https://github.com/PufferAI/PufferLib/blob/experimental/cleanrl_ppo_atari.py">here</a></p>
<p>PufferLib also includes a heavily customized version of CleanRL PPO with support for recurrent and non-recurrent models, async environment execution, variable agent populations, self-play, and experiment management. This is the version we use for our research and the NeurIPS 2023 Neural MMO Competition. You can try it out <a class="reference external" href="https://github.com/PufferAI/PufferLib/blob/experimental/clean_pufferl.py">here</a></p>
<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/anyscale/ray" target="_blank">
            <img src="https://img.shields.io/github/stars/ray-project/ray?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Ray" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://docs.ray.io/">Ray</a> is a general purpose distributed computing framework that includes <a href="https://docs.ray.io/en/latest/rllib">RLlib</a>, an industry reinforcement learning library.</p>
    </div>
</div><p>We have previously supported RLLib and may again in the future. RLlib has not received updates in a while, and the current release is very buggy. We will update this if the situation improves.</p>
</section>
<section id="environments">
<h1>Environments<a class="headerlink" href="#environments" title="Permalink to this heading">#</a></h1>
<p>PufferLib ships with Ocean, our first-party testing suite. We also provide integrations for many environments out of the box. Non-pip dependencies are already set up for you in PufferTank. Several environments also include reasonable baseline policies. Join our Discord if you would like to add setup and tests for new environments or improvements to any of the baselines.</p>
<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/openai/gym" target="_blank">
            <img src="https://img.shields.io/github/stars/openai/gym?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star OpenAI Gym" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/openai/gym">OpenAI Gym</a> is the standard API for single-agent reinforcement learning environments. It also contains some built-in environments. We include <a href="https://www.gymlibrary.dev/environments/box2d/">Box2D</a> in our registry.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/PWhiddy/PokemonRedExperiments" target="_blank">
            <img src="https://img.shields.io/github/stars/PWhiddy/PokemonRedExperiments?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Pokemon Red" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/PWhiddy/PokemonRedExperiments">Pokemon Red</a> is one of the original Pokemon games for gameboy. This project uses the game as an environment for reinforcement learning. We are actively supporting development on this one!</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/Farama-Foundation/PettingZoo" target="_blank">
            <img src="https://img.shields.io/github/stars/Farama-Foundation/PettingZoo?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star PettingZoo" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://pettingzoo.farama.org">PettingZoo</a> is the standard API for multi-agent reinforcement learning environments. It also contains some built-in environments. We include <a href="https://pettingzoo.farama.org/environments/butterfly/">Butterfly</a> in our registry.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/Farama-Foundation/Arcade-Learning-Environment" target="_blank">
            <img src="https://img.shields.io/github/stars/Farama-Foundation/Arcade-Learning-Environment?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Arcade Learning Environment" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/Farama-Foundation/Arcade-Learning-Environment">Arcade Learning Environment</a> provides a Gym interface for classic Atari games. This is the most popular benchmark for reinforcement learning algorithms.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/Farama-Foundation/Minigrid" target="_blank">
            <img src="https://img.shields.io/github/stars/Farama-Foundation/Minigrid?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Minigrid" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/Farama-Foundation/Minigrid">Minigrid</a> is a 2D grid-world environment engine and a collection of builtin environments. The target is flexible and computationally efficient RL research.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/geek-ai/MAgent" target="_blank">
            <img src="https://img.shields.io/github/stars/geek-ai/MAgent?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star MAgent" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/geek-ai/MAgent/blob/master/doc/get_started.md">MAgent</a> is a platform for large-scale agent simulation.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/neuralmmo/environment" target="_blank">
            <img src="https://img.shields.io/github/stars/openai/neural-mmo?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Neural MMO" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://neuralmmo.github.io">Neural MMO</a> is a massively multiagent environment for reinforcement learning. It combines large agent populations with high per-agent complexity and is the most actively maintained (by me) project on this list.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/openai/procgen" target="_blank">
            <img src="https://img.shields.io/github/stars/openai/procgen?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Procgen" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/openai/procgen">Procgen</a> is a suite of arcade games for reinforcement learning with procedurally generated levels. It is one of the most computationally efficient environments on this list.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/facebookresearch/nle" target="_blank">
            <img src="https://img.shields.io/github/stars/facebookresearch/nle?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star NLE" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/facebookresearch/nle">Nethack Learning Environment</a> is a port of the classic game NetHack to the Gym API. It combines extreme complexity with high simulation efficiency.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/facebookresearch/minihack" target="_blank">
            <img src="https://img.shields.io/github/stars/facebookresearch/minihack?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star MiniHack" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/facebookresearch/nle">MiniHack Learning Environment</a> is a stripped down version of NetHack with support for level editing and custom procedural generation.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/danijar/crafter" target="_blank">
            <img src="https://img.shields.io/github/stars/danijar/crafter?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Crafter" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/danijar/crafter">Crafter</a> is a top-down 2D Minecraft clone for RL research. It provides pixel observations and relatively long time horizons.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/Bam4d/Griddly" target="_blank">
            <img src="https://img.shields.io/github/stars/Bam4d/Griddly?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star Griddly" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://griddly.readthedocs.io/en/latest/">Griddly</a> is an extremely optimized platform for building reinforcement learning environments. It also includes a large suite of built-in environments.</p>
    </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 15px;">
    <div style="flex-shrink: 0; width: 100px; margin-right: 20px;">
        <a href="https://github.com/Farama-Foundation/MicroRTS-Py" target="_blank">
            <img src="https://img.shields.io/github/stars/Farama-Foundation/MicroRTS-Py?labelColor=999999&color=66dcdc&cacheSeconds=100000" alt="Star MicroRTS-Py" width="100px">
        </a>
    </div>
    <div>
        <p><a href="https://github.com/Farama-Foundation/MicroRTS-Py">Gym MicroRTS</a> is a real time strategy engine for reinforcement learning research. The Java configuration is a bit finicky -- we're still debugging this.</p>
    </div>
</div></section>
<section id="current-limitations">
<h1>Current Limitations<a class="headerlink" href="#current-limitations" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>No continuous action spaces (WIP)</p></li>
<li><p>Support for heterogenous observations and actions requires you to specify teams such that each team has the same observation and action space. There’s no good way around this.</p></li>
</ul>
</section>
<section id="license">
<h1>License<a class="headerlink" href="#license" title="Permalink to this heading">#</a></h1>
<p>PufferLib is free and open-source software under the MIT license. This is the full set of tools maintained by PufferAI. Dev branches are public and we do not have private repositories with additional utilities.</p>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="api.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Emulation</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Home</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Joseph Suarez
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/design-tabs.js"></script>
    </body>
</html>